apiVersion: v1
kind: ConfigMap
metadata:
  name: llamastack-config
  namespace: catalystlab-shared
data:
  config.yaml: |
    version: '2'
    image_name: starter
    apis: [inference, agents, tool_runtime, vector_io, files]
    providers:
      inference:
        - provider_id: vllm
          provider_type: "remote::vllm"
          config:
            base_url: ${env.VLLM_URL}
            max_tokens: ${env.VLLM_MAX_TOKENS:=4096}
            api_token: ${env.VLLM_API_TOKEN:=fake}
      vector_io:
        - provider_id: pgvector
          provider_type: "remote::pgvector"
          config:
            host: ${env.PGVECTOR_HOST}
            port: ${env.PGVECTOR_PORT:=5432}
            db: ${env.PGVECTOR_DB}
            user: ${env.PGVECTOR_USER}
            password: ${env.PGVECTOR_PASSWORD}
            persistence:
              namespace: vector_io::pgvector
              backend: kv_default
      agents:
        - provider_id: meta-reference
          provider_type: "inline::meta-reference"
          config:
            persistence:
              agent_state:
                namespace: agents
                backend: kv_default
              responses:
                table_name: agent_responses
                backend: sql_default
                max_write_queue_size: 10000
                num_writers: 4
      tool_runtime:
        - provider_id: model-context-protocol
          provider_type: "remote::model-context-protocol"
          config: {}
      files:
        - provider_id: meta-reference-files
          provider_type: "inline::localfs"
          config:
            storage_dir: /.llama/files
            metadata_store:
              table_name: files_metadata
              backend: sql_default
    storage:
      backends:
        kv_default:
          type: kv_postgres
          host: ${env.POSTGRES_HOST}
          port: ${env.POSTGRES_PORT:=5432}
          db: ${env.POSTGRES_DB}
          user: ${env.POSTGRES_USER}
          password: ${env.POSTGRES_PASSWORD}
          table_name: llamastack_kvstore
        sql_default:
          type: sql_postgres
          host: ${env.POSTGRES_HOST}
          port: ${env.POSTGRES_PORT:=5432}
          db: ${env.POSTGRES_DB}
          user: ${env.POSTGRES_USER}
          password: ${env.POSTGRES_PASSWORD}
      stores:
        metadata:
          namespace: registry
          backend: kv_default
        inference:
          table_name: inference_store
          backend: sql_default
          max_write_queue_size: 10000
          num_writers: 4
        conversations:
          table_name: openai_conversations
          backend: sql_default
        prompts:
          namespace: prompts
          backend: kv_default
        connectors:
          namespace: connectors
          backend: kv_default
    models:
      - model_id: "${env.MODEL_NAME}"
        provider_id: vllm
        model_type: llm
    server:
      port: 8321
